{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction of concrete strength using ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO9RwqZi8h1R"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rps18cno80ph"
      },
      "source": [
        "df=pd.read_csv('Concrete_Data_Yeh.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMGIhGgj9NYG"
      },
      "source": [
        "x=df.iloc[:,0:-1].values\n",
        "y=df.iloc[:,-1].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzguWX629WAW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x,y,test_size=.2,random_state=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TOtGg9h9-5Z"
      },
      "source": [
        "ann=tf.keras.Sequential()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i40MMeSe-qOP"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heUELQoX-5GW"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n99_7vV--Zf"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaA648FY_IwG"
      },
      "source": [
        "ann.compile(optimizer='adam',loss='mean_squared_error')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH3s5rAC_W9-",
        "outputId": "a97ece33-f58b-46fe-bcb9-cf25d69f692e"
      },
      "source": [
        "ann.fit(xtrain,ytrain,epochs=100,batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 125.2034\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 124.5148\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 124.0865\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 123.7913\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 123.3742\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 122.9871\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 122.6395\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 122.3032\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 121.8657\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 121.5121\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 121.1826\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 120.7567\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 120.2022\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 120.0040\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 119.7694\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 119.1035\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 118.6360\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 118.1318\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 117.7623\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 117.4499\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 116.9883\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 116.6725\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 116.0000\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 115.5895\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 115.1731\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 114.6232\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 114.2088\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 113.7210\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 113.5455\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 112.8035\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 112.4841\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 112.1132\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 111.7581\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 111.3704\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 110.9822\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 110.3768\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 110.2053\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 109.9174\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 109.4444\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 108.8416\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 108.4697\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 108.0263\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 107.6699\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 106.9780\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 106.7940\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 106.1336\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 105.9111\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 105.3311\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 104.6929\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 104.2229\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 103.7826\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 103.5139\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 102.8249\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 102.2685\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 102.0365\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 101.2584\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 100.9048\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 100.5827\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 99.9941\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 99.3917\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 98.9315\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 98.5714\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 98.0904\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 97.5309\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 97.0324\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 96.5598\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 96.2196\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 95.7043\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 95.2581\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 94.8994\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 94.4485\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 93.9999\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 93.4445\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 93.0794\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 92.6291\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 92.2576\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 91.9805\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 91.4175\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 90.9848\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 90.6356\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 90.2848\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 89.9177\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 89.6521\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 89.5703\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 89.0477\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 88.5532\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 88.0352\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 87.6667\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 87.3825\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 86.9886\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 86.4931\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 86.1550\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 85.8882\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 85.4800\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 85.1096\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 84.9296\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 84.5618\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 84.0826\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 83.8546\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 83.4226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f53bdbe81d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhNEYiYjAhBB"
      },
      "source": [
        "pred=ann.predict(xtest)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSMU0AgTAnEW",
        "outputId": "e4cdfa1d-4596-44ef-968f-f7ab204ae976"
      },
      "source": [
        "print(np.concatenate((ytest.reshape(len(ytest),1),pred.reshape(len(pred),1)),axis=1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[26.06       37.74726486]\n",
            " [10.35       18.86640167]\n",
            " [79.3        71.9625473 ]\n",
            " [74.99       62.19956207]\n",
            " [ 9.69       28.76317596]\n",
            " [47.1        55.50047302]\n",
            " [59.         54.68544388]\n",
            " [22.72       24.88529205]\n",
            " [61.89       61.10782242]\n",
            " [52.12       38.07215118]\n",
            " [17.54       17.16512108]\n",
            " [48.15       48.76385117]\n",
            " [38.33       30.62810898]\n",
            " [17.2        37.8088913 ]\n",
            " [56.83       47.39002228]\n",
            " [55.25       61.90668869]\n",
            " [33.36       33.39994431]\n",
            " [34.68       31.17181969]\n",
            " [52.61       53.68656921]\n",
            " [39.94       33.41415787]\n",
            " [61.46       55.97281647]\n",
            " [27.63       29.79395103]\n",
            " [32.9        33.71121979]\n",
            " [41.64       52.78275681]\n",
            " [17.54       25.30872917]\n",
            " [26.85       23.48402023]\n",
            " [66.9        60.97964096]\n",
            " [21.06       26.48282051]\n",
            " [61.07       61.90668869]\n",
            " [66.95       58.98119736]\n",
            " [20.87       18.43968391]\n",
            " [48.79       42.3937645 ]\n",
            " [24.05       18.29099464]\n",
            " [47.81       29.621521  ]\n",
            " [21.16       26.47603226]\n",
            " [ 6.94       17.15756035]\n",
            " [28.6        54.56671906]\n",
            " [26.31       25.96807671]\n",
            " [33.95       29.11858559]\n",
            " [25.72       25.73854446]\n",
            " [37.8        54.57954407]\n",
            " [35.17       33.08805084]\n",
            " [32.24       20.1352005 ]\n",
            " [37.81       34.60400009]\n",
            " [57.23       58.24025345]\n",
            " [33.4        51.03927994]\n",
            " [30.14       31.74255562]\n",
            " [33.8        44.72314835]\n",
            " [35.08       36.65375519]\n",
            " [52.91       48.81907272]\n",
            " [40.93       43.18095016]\n",
            " [21.75       19.36352348]\n",
            " [16.5        27.84576797]\n",
            " [42.35       36.04473877]\n",
            " [50.94       47.14643097]\n",
            " [64.02       47.28756714]\n",
            " [52.2        38.71389008]\n",
            " [53.39       56.44624329]\n",
            " [64.3        62.70424271]\n",
            " [44.52       38.32912827]\n",
            " [37.42       34.18390274]\n",
            " [22.14       16.57187653]\n",
            " [62.94       51.34572983]\n",
            " [45.7        50.80678558]\n",
            " [14.64       19.49697113]\n",
            " [53.58       54.00019836]\n",
            " [33.72       35.0663147 ]\n",
            " [24.58       36.40032196]\n",
            " [13.2        16.43929291]\n",
            " [18.91       20.49135017]\n",
            " [ 7.4        25.90702248]\n",
            " [24.85       26.38263321]\n",
            " [49.2        51.91965103]\n",
            " [25.57       22.64649963]\n",
            " [31.38       33.64251709]\n",
            " [23.35       50.24172592]\n",
            " [45.71       29.64775848]\n",
            " [ 6.81       20.70802689]\n",
            " [27.34       24.19390297]\n",
            " [39.59       28.78017807]\n",
            " [30.96       21.91980553]\n",
            " [55.64       49.87644577]\n",
            " [18.02       33.21155167]\n",
            " [33.09       32.05700302]\n",
            " [48.72       39.57678223]\n",
            " [36.8        36.50786209]\n",
            " [45.9        43.94591522]\n",
            " [46.68       49.81019592]\n",
            " [40.87       39.03314209]\n",
            " [35.34       35.91486359]\n",
            " [65.7        57.23200226]\n",
            " [17.24       20.1557045 ]\n",
            " [ 9.45       22.43591881]\n",
            " [33.94       36.48125458]\n",
            " [15.57       25.55836678]\n",
            " [40.27       49.3171463 ]\n",
            " [15.82       29.03724289]\n",
            " [41.54       39.90625763]\n",
            " [50.24       48.35182953]\n",
            " [29.98       29.69647408]\n",
            " [20.73       30.55833435]\n",
            " [27.42       38.56034851]\n",
            " [27.66       25.92402649]\n",
            " [29.73       33.69996643]\n",
            " [45.08       38.80109787]\n",
            " [42.13       39.83240509]\n",
            " [51.96       40.5508194 ]\n",
            " [15.61       28.06828117]\n",
            " [34.29       30.08084679]\n",
            " [53.52       41.97109604]\n",
            " [ 4.83       22.26289749]\n",
            " [41.37       54.39067841]\n",
            " [ 9.73       26.57149887]\n",
            " [31.81       32.27099609]\n",
            " [41.05       45.61014557]\n",
            " [61.92       61.71902847]\n",
            " [37.42       34.48027802]\n",
            " [37.92       45.75894547]\n",
            " [32.72       40.08164215]\n",
            " [14.94       29.84581375]\n",
            " [44.09       42.41637421]\n",
            " [26.92       33.78386688]\n",
            " [64.9        63.38119507]\n",
            " [29.22       24.40391922]\n",
            " [12.46       17.55143547]\n",
            " [ 8.         22.04475403]\n",
            " [13.71       16.81598473]\n",
            " [13.66       23.92540741]\n",
            " [63.14       42.17362595]\n",
            " [37.91       32.09785843]\n",
            " [37.4        27.97281456]\n",
            " [55.06       44.52832794]\n",
            " [35.23       30.3328476 ]\n",
            " [31.42       27.78978157]\n",
            " [10.73       21.68474388]\n",
            " [47.97       54.73050308]\n",
            " [38.89       56.1196785 ]\n",
            " [38.8        39.50143433]\n",
            " [ 4.57       17.64230537]\n",
            " [10.39       22.57850266]\n",
            " [29.59       36.55443573]\n",
            " [54.38       42.62335587]\n",
            " [22.5        28.36518097]\n",
            " [28.63       27.96856117]\n",
            " [17.34       17.23147202]\n",
            " [32.33       34.73714828]\n",
            " [41.67       45.18823242]\n",
            " [15.87       23.93703651]\n",
            " [44.86       30.85412598]\n",
            " [17.54       16.97545433]\n",
            " [11.98       20.26982689]\n",
            " [15.42       22.26431656]\n",
            " [30.39       26.3796196 ]\n",
            " [45.85       28.28484726]\n",
            " [41.68       35.32523727]\n",
            " [42.64       30.77803802]\n",
            " [34.9        47.07652664]\n",
            " [25.45       32.31509399]\n",
            " [39.3        34.11595917]\n",
            " [27.92       24.06579018]\n",
            " [52.5        39.77054596]\n",
            " [37.81       43.80555725]\n",
            " [15.53       15.96040344]\n",
            " [30.57       27.06750679]\n",
            " [37.36       40.94582367]\n",
            " [14.59       24.81252289]\n",
            " [53.69       50.09177017]\n",
            " [57.03       55.74407196]\n",
            " [55.26       50.7240448 ]\n",
            " [ 6.47       11.17134953]\n",
            " [33.42       40.09835434]\n",
            " [41.16       34.55085373]\n",
            " [31.45       26.40419006]\n",
            " [36.15       53.2918129 ]\n",
            " [14.4        26.67147064]\n",
            " [13.36       17.18120384]\n",
            " [ 8.54       15.57121181]\n",
            " [40.29       50.29111481]\n",
            " [32.04       25.22023964]\n",
            " [51.43       41.53619385]\n",
            " [21.48       36.9672699 ]\n",
            " [29.72       33.84605408]\n",
            " [14.2        19.43871498]\n",
            " [37.68       45.25150681]\n",
            " [24.13       33.08457184]\n",
            " [23.85       39.82555771]\n",
            " [36.45       40.6256752 ]\n",
            " [44.28       42.54137421]\n",
            " [19.52       26.99957466]\n",
            " [59.49       51.34572983]\n",
            " [25.18       21.35917282]\n",
            " [69.3        67.14227295]\n",
            " [61.23       50.99161148]\n",
            " [32.92       30.26018333]\n",
            " [ 6.28       20.0848732 ]\n",
            " [39.7        24.77983284]\n",
            " [33.4        37.81702805]\n",
            " [23.84       26.64346504]\n",
            " [39.27       32.0713501 ]\n",
            " [72.3        62.84839249]\n",
            " [18.13       17.17930031]\n",
            " [27.53       23.55562782]\n",
            " [33.76       38.54676056]\n",
            " [33.01       32.93338013]\n",
            " [33.72       35.21084976]\n",
            " [13.82       18.84660721]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1IIqmV7BBrG",
        "outputId": "cf38b447-31dd-4eaf-f402-d0187fdc8ebb"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(ytest,pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7044603298004108"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MpmIM6gBUw9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}